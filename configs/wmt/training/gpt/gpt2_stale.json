{
    "method": "baseline",
    "dataset_version": "full",
    "learning_rate": 1e-3,
    "freeze_level": 0,
    "t5_learning_rate": null,
    "num_train_epochs": 1,
    "output_dir": "outputs/wmt/gpt",
    "wandb_log": true,
    "train_batch_size": 32,
    "resume_from_checkpoint": false,
    "mask_mode": "causal",
    
    "ngpu": 4,
    "strategy": "ddp",
    "precision": 32,
    "use_profiler": false,

    "input_length": 100,
    "output_length": 100,
    "dataset": "wmt",
    "prefix": true,
    "model": "gpt2-large",
    "num_workers": 0,
    "wandb_project": "temporal_questions",
    "wandb_run_name": "baseline_2010",
    "mode": "pretrain",
    "use_lr_scheduling": true,
    "check_validation": false,
    "checkpoint_path": "",
    "output_hidden_states": true
}
