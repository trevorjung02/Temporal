{
    "input_length" : 150,
    "output_length" : 10,
    "num_train_epochs" : 1,
    "output_dir" : "",
    "dataset" : "newlama_easy",
    "dataset_version" : "small",
    "train_batch_size" : 32,
    "learning_rate" : 1e-3,
    "model" : "google/t5-large-ssm",
    "method": "lora",
    "freeze_level": 0,
    "gradient_accumulation_steps" : 3,
    "ngpu" : 1,
    "num_workers" : 40,
    "resume_from_checkpoint" : null,
    "accelerator" : "ddp",
    "use_deepspeed" : false,
    "CUDA_VISIBLE_DEVICES" : "2",
    "wandb_log": false,
    "wandb_project": "continual_learning_evaluation",
    "wandb_run_name" : "T5_large_recentnews(small)_lr.001_lora",
    "mode" : "pretrain",
    "use_lr_scheduling" : false,
    "check_validation" : true,
    "checkpoint_path" : "outputs/split/lora2.ckpt",
    "output_log" : "log/newLAMA_Easy1/lora2.csv",
    "split_num" : 2,
    "split" : 1
}
