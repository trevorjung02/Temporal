#!/bin/bash
#SBATCH --job-name=data-proc
#SBATCH --partition=gpu-2080ti
#SBATCH --account=ark
#SBATCH --nodes=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=32G
#SBATCH --gres=gpu:1
#SBATCH --time=12:00:00 
#SBATCH --mail-type=ALL
#SBATCH --mail-user=tjung2@uw.edu

# I use source to initialize conda into the right environment.
cat $0
echo "--------------------"

source ~/.bashrc
conda activate ckl

# python run.py --config configs/templama/training/t5_kadapters_yearly_2freeze.json -checkpoint_path outputs/wmtbaseline_full/epoch=0-f1_score=0.151-em_score=0.000.ckpt

# python run.py --config configs/wmt/training/t5_kadapters_yearly_2freeze.json -checkpoint_path outputs/wmtkadapter_2010_2freeze_158_128/epoch=8-f1_score=0.084-em_score=0.000.ckpt

python preprocess_wmt_train_data.py 2016
python preprocess_wmt_train_data.py 2017
python preprocess_wmt_train_data.py 2018
--------------------
number of articles: 803316
300000 articles loaded
Read csv: 22.882637128 seconds
decode sentences: 4.790573986000005 seconds
Create sentences: 1.5942903669999993 seconds
total sentences 8590337
Run spacy on sentences: 4.504999999710435e-06 seconds
Construct datasets: 412.58902878900005 seconds
max input length = 199
max output length = 2
Write datasets: 1.7953390610000497 seconds
number of articles: 5251273
300000 articles loaded
Read csv: 123.143136287 seconds
decode sentences: 5.40985526099999 seconds
Create sentences: 1.8382349769999848 seconds
total sentences 10261155
Run spacy on sentences: 4.669000020385283e-06 seconds
Construct datasets: 412.027331869 seconds
max input length = 1242
max output length = 2
Write datasets: 1.7138344129999723 seconds
number of articles: 2283184
300000 articles loaded
Read csv: 55.944309469000004 seconds
decode sentences: 5.318631412000002 seconds
Create sentences: 1.781934487000001 seconds
total sentences 9956823
Run spacy on sentences: 4.5860000028596914e-06 seconds
Construct datasets: 409.197496085 seconds
max input length = 373
max output length = 2
Write datasets: 1.7220730060000164 seconds
